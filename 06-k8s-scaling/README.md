### Introducci칩n

Google Kubernetes Engine (GKE) ofrece herramientas de autoescalado 
horizontal y vertical tanto para PODs como para la infraestructura
en general. Estas soluciones de autoescalado son de suma importancia
cuando queremos hacer un uso de GKE eficiente y optimizado en cuanto a 
costes se refiere. En este ejemplo pretendemos precisamente que seas
capaz de poner en marcha, y observar, un autoescalado horizontal (HPA,
del ingl칠s *Horizontal Pod Autoscaling*)
y vertical de pods (VPA, del ingl칠s *Vertical Pod Autoscaling*), 
adem치s de un escalado a nivel del cluster (*Cluster Autoscaler*,
escalado horizontal de la infraestructura) y de *nodo*
(*Node Auto Provisioning*, escalado vertical de la infraestructura).
Vamos a utilizar estas *herramientas* con el objetivo de ahorrar 
costes de infraestructura, mediante la reducci칩n del tama침o del 
cluster (o de los nodos) en momentos de baja demanda. Aunque
tambi칠n ser치n utilizadas para aumentar la infraestructura en intervalos
de muy alta demanda, lo cual forzaremos en nuestro ejemplo para ver
como estas herramientas hacen posible tener una infraestructura
completamente flexible y din치mica.

Para ello, vamos a proceder siguiendo los pasos que se enumeran:

* Crearemos un cluster de K8s que estar치 sirviendo un webserver de apache

* Aplicaremos una pol칤tica de autoescalado horizontal y vertical para:

    - Reducir el numero de r칠plicas de un *Deployment* con HPA
    
    - Reducir la CPU asignada a un *Deployment* con VPA

* Aplicaremos una pol칤tica de autoescalado horizontal a nivel de cluster con *Cluster Autoscaler*

* Usaremos NAP para que se cree un pool de nodos optimizado a la carga de nuestro cluster

* Test del comportamiento de las diferentes configuraciones de autoescalado 
  ante un aumento repentino de demanda

Todos estos pasos se desglosan a continuaci칩n (y se pueden encontrar en
el script de despliegue: [deployment.sh](deployment.sh))

### 1. Creaci칩n del cluster GKE
Lo primero que vamos a hacer es asegurarnos de tener configurada una
zona de procesamiento predeterminada. Para establecer nuestra zona de procesamiento
predeterminada en `us-central1-a` ejecutaremos el siguiente comando:

```shell
$ gcloud config set compute/zone $zone
```

丘멆잺 Como hemos hecho en otras ocasiones, las variables de configuraci칩n las hemos
guardado en un manifiesto de configuraci칩n, [config.ini](config.ini). Para poder
tenerlas disponibles en nuestro script, usamos:
```shell
> source "${PWD}/config.ini"
```
al inicio del mismo.


Una vez configurada la zona por defecto, vamos a proceder a crear un cluster GKE.
칄ste constar치 de, al menos, una instancia principal y varias VMs que ejecutar치n los procesos de
Kubernetes, llamadas en este contexto nodos. As칤, los nodos son VMs de Compute Engine que ejecutan los procesos de Kubernetes necesarios.

A continuaci칩n vamos a crear nuestro cluster, el cual tendr치 el nombre que queramos especificar
en la variable `$cluster_name`:

```shell
$ gcloud container clusters create "$cluster_name" \
  --num-nodes=3 \
  --enable-vertical-pod-autoscaling \
  --release-channel=rapid
```
La creaci칩n del cl칰ster podr치 llevar varios minutos.

Para demostrar el autoescalado horizontal de pods vamos a desplegar
una imagen de docker basada en `php-apache`. 칄sta servir치 un 
`index.php` que lleva a cabo tareas computacionalmente costosas.
Para esto, vamos a hacer uso de un manifiesto de despliegue, 
[php-apache.yaml](php-apache.yaml), que contiene la siguiente 
configuraci칩n:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: php-apache
spec:
  selector:
    matchLabels:
      run: php-apache
  replicas: 3
  template:
    metadata:
      labels:
        run: php-apache
    spec:
      containers:
      - name: php-apache
        image: k8s.gcr.io/hpa-example
        ports:
        - containerPort: 80
        resources:
          limits:
            cpu: 500m
          requests:
            cpu: 200m
---
apiVersion: v1
kind: Service
metadata:
  name: php-apache
  labels:
    run: php-apache
spec:
  ports:
  - port: 80
  selector:
    run: php-apache
```
Una vez haya terminado la creaci칩n del cluster, aplicaremos
este manifiesto mediante:

```shell
$ kubectl apply -f "$php_manifest"
```

### 2. Escalado de pods con HPA

HPA (o autoescalado horizontal de pods) se encarga de 
modificar la estructura de nuestro cluster mediante el incremento
o decremento autom치tico del n칰mero de pods en respuesta a la 
carga CPU de trabajo que haya, o al consumo de memoria, o en 
respuesta a ciertas m칠tricas personalizadas que son monitorizadas
por K8s y que podemos usar como indicadores de un cambio de regimen.

Para comenzar esta tarea comenzamos inspeccionando los 
despliegues que se encuentran en funcionamiento en nuestro cluster:

```shell
$ kubectl get deployment
```

Esto nos deber칤a mostrar en terminal que tenemos un despliegue 
llamado `php-apache` y que hay `3/3` pods funcionando de manera
correcta.

丘멆잺 Si por lo que fuera no vemos los 3 pods que esperamos en funcionamiento,
espera un par de minutos, y vuelve a intentarlo una vez pasado este tiempo.
Si ves `1/1`, puede ser que hayas dejado suficiente tiempo pasar como
para que el despliegue haya escalado a la baja.


Una vez hemos comprobado que el despliegue est치 correctamente
funcionando, vamos a aplicar el HPA:

```shell
$ kubectl autoscale deployment $php_deployment \
  --cpu-percent="$cpu_threshold" \
  --min="$min_replicas" \
  --max="$max_replicas"
```
(recuerda, las variables est치n definidas en el archivo [config.ini](config.ini)).

Este comando configura un HPA que mantendr치 gestionadas entre `$min_replicas`
y `max_replicas` replicas de los pods controlados por el despliegue `php_deployment`.
La opci칩n `--cpu-percent` establece el objetivo de uso de CPU promedio 
en todos los pods. Es decir, el HPA adaptar치 el n칰mero de r칠plicas
(mediante despliegue) para mantener un uso promedio de CPU de un `$cpu_threshold` 
(en procentaje, e.g. `--cpu-percent=50` significa `50%`).

Una vez el HPA est치 configurado, podemos comprobar el estado del mismo
mediante:

```shell
$ kubectl get hpa
```

Deber칤amos ver `0%/50%` bajo la columna `Targets`. Esto significa
que ahora mismo el promedio de CPU usada por pod es de un 0$%, 
lo cual es de esperar dado que la app `php-apache` no est치 recibiendo
ning칰n tr치fico a estas alturas. A su vez, a medida que el HPA
entra en acci칩n veremos que la columna `Replicas` cambia de valores.
Inicialmente estar치 a 3, pero a medida que pasa el tiempo (entre
5 y 10 minutos), el HPA reducir치 el n칰mero de r칠plicas dado que el
uso de CPU est치 por debajo del umbral establecido.


### 3. Escalado vertical de pods con VPA

VPA (o autoescalado vertical de pods) nos libera de la responsabilidad
de tener que conocer perfectamente los valores de CPU que 
tenemos que seleccionar para cada contenedor. De hecho, el auto-escalador
VPA nos recomienda valores de CPU y RAM, y l칤mites, acorde
al hist칩rico de uso. Adem치s, evidentemente, puede hacer que
susodichos valores sean los que se utilicen en los nodos del
despliegue.

游뚿 *Atenci칩n*: No deber칤amos usar nunca un VPA y un HPA simult치neamente
sobre la misma m칠trica (CPU o memoria). La raz칩n es sencilla, si
as칤 fuera, ambos auto-escaladores intentar칤an responder al cambio
de demanda en la misma m칠trica y llevar칤a a un conflicto de 
responsabilidades. No obstante, s칤 que se pueden usar (y se
recomienda de hecho) en distintas, por ejemplo VPA en CPU o memoria
y el HPA en m칠tricas personalizadas para evitar el solapamiento.


Si recuerdas, cuando hemos creado el cluster, hemos seleccionado
la opci칩n de autoescalado vertical. Es por ello que VPA ya est치
activo en nuestro cluster. Para comprobarlo, solo tenemos que
ejecutar el siguiente comando:

```shell
$ gcloud container clusters describe scaling-demo | grep ^verticalPodAutoscaling -A 1
```

Este comando nos deber칤a devolver en terminal: `enabled: true`,
confirmando que est치 activo. Si por lo que fuera se nos olvid칩 
activarlo con la creaci칩n del cluster, podemos hacerlo ahora de 
forma manual:

```shell
$ gcloud container clusters update $cluster_name \
    --enable-vertical-pod-autoscaling
```

Para comprobar las virtudes de VPA, vamos a desplegar un nuevo
servicio, `hello-server`:

```shell
$ kubectl create deployment hello-server \
    --image=gcr.io/google-samples/hello-app:1.0
```

Esto llevar치 unos minutos. Cuando acabe el despliegue, 
podremos asegurarnos de que todo ha ido bien mediante el
siguiente comando:

```shell
$ kubectl get deployment hello-server
```

A continuaci칩n, vamos a definir la m칤nima cantidad de CPU
necesaria por el despliegue `hello-server`. En el lenguaje
de K8s esto se conoce como *resource requests* (RR). Por ejemplo,
vamos a comenzar seleccionando un RR de 450 mili-CPU, i.e. 0.45 CPUs.
Esto se lleva a cabo mediante:

```shell
$ kubectl set resources deployment hello-server \
  --requests=cpu=450m
```

Ahora podemos inspeccionar el pod que sirve `hello-server`
y ver que la configuraci칩n de `Requests` es precisamente
la que acabamos de configurar:

```shell
$ kubectl describe pod hello-server | sed -n "/Containers:$/,/Conditions:/p"
```

En lo que sigue, vamos a usar el manifiesto de configuraci칩n del
VPA, [hello-vpa.yaml](hello-vpa.yaml):

```yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: hello-server-vpa
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind:       Deployment
    name:       hello-server
  updatePolicy:
    updateMode: "Off"
```

Este manifiesto generar치 un auto-esclador VPA para el 
despliegue `hello-server` con una pol칤tica de actualizaci칩n 
`Off`. Un VPA solo puede tener una de las siguientes tres
pol칤ticas de actualizaci칩n:

- *Off*: Con esta configuraci칩n VPA solo generar치 recomendaciones
  basadas en datos hist칩ricos. Dichas recomendaciones no ser치n
  aplicadas, las tendremos que aplicar nosotros manualmente
- *Initial*: VPA generar치 recomendaciones y crear치 nuevos pods
  basadas en las mismas una sola vez, no cambiar치 el tama침o de los
  pods a posteriori
- *Auto*: VPA borrar치 y crear치 regularmente pods para que se cumplan
  las recomendaciones actualizadas regularmente
  
Conocido esto, apliquemos el manifiesto mencionado:

```shell
$ kubectl apply -f hello-vpa.yaml
```

Tras esperar un minuto, aproximadamente, podemos hacer una comprobaci칩n
del VPA mediante:

```shell
$ kubectl describe vpa hello-server-vpa
```

Dado que nuestro manifiesto especificaba una pol칤tica de 
actualizaci칩n modo `Off`, lo que podremos ver ser치n las recomendaciones
generadas por la VPA. Para ello, podemos fijarnos en la secci칩n
`Container Recommendations` que deber칤a aparecernos al final de
la respuesta del anterior comando. Ah칤 veremos diferentes
tipos de recomendaci칩n, cada uno de ellos con valores de CPU
y memoria. Si todo ha ido bien, veremos que el VPA nos est치 
recomendando que bajemos la CPU RR a `25m`, en lugar del valor
previo, adem치s de darnos un valor de cuanta memoria deber칤a
requerirse. A partir de aqu칤, podr칤amos aplicar estas recomendaciones
manualmente. 

丘멆잺 Las recomendaciones dadas por el VPA vienen dadas en base
a los datos recolectados, por lo que para 칠stas sean lo m치s
칰tiles posibles, deber칤amos esperar a recolectar aproximadamente 
unas 24h si estamos en el modo `Off`.

En lugar de aplicar las recomendaciones manualmente, vamos a 
proceder a cambiar la pol칤tica de actualizaci칩n del VPA.
Para ello ya tenemos preparado el manifiesto modificado
en [hello-vpa-auto.yaml](hello-vpa-auto.yaml):

```yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: hello-server-vpa
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind:       Deployment
    name:       hello-server
  updatePolicy:
    updateMode: "Auto"
```

Lo 칰nico que tenemos que hacer es actualizar el VPA
con el manifiesto mencionado mediante el siguiente comando:

```shell
$ kubectl apply -f hello-vpa-auto.yaml
```

Para que el VPA pueda adaptar el tama침o del pod, 
primero necesitar치 borra el pod y posteriormente recrearlo
con la nueva configuraci칩n de tama침o. 
Por configuraci칩n de defecto, VPA no va a borrar el 
칰ltimo pod activo, que es el que estamos estudiando. As칤
que necesitaremos al menos 2 r칠plicas para ver como el VPA
hace los cambios adecuados. Para ello, vamos a escalar
nosotros manualmente ahora el despliegue `hello-server` 
a dos r칠plicas:

```shell
$ kubectl scale deployment hello-server --replicas=2
```

A continuaci칩n, podemos monitorizar el comportamiento de los
pods mediante:

```shell
$ kubectl get pods -w
```

Esperamos hasta que veamos los pods `hello-server-xxx` en
el estado `terminating`. Esta es la se침al de que nuestra VPA
ya est치 borrando y reconfigurando el tama침o de los pods.
Una vez que lo veamos podremos simplemente salir de la espera
pulsando `Ctrl + c` en nuestro terminal.

### 4. Comprobaci칩n de los autoescaladores HPA y VPA

#### HPA
A estas alturas, el HPA ya habr치 escalado nuestro despliegue 
`php-apache` para optimizar recursos. Para comprobarlo
simplemente tenemos que ejecutar:

```shell
$ kubectl get hpa
```

Si miramos el n칰mero de r칠plicas en la columna correspondiente
veremos que HPA ha reducido el n칰mero de estas a 1.
Lo que ha ocurrido es que el HPA ha detectado que no hay ninguna
actividad en esta app, y por tanto ha liberado recursos.
Sin embargo, si hubiese demanda en esta aplicaci칩n entonces
HPA escalar칤a de nuevo hacia arriba. Como podemos observar,
esto es muy conveniente a la hora de optimizar costes.

#### VPA

Pasado unos minutos, el auto-escalador VPA habr치 ya entrado
en juego y re-escalado los pods. Para ver si es as칤 podemos
comprobarlo mediante:

```shell
$ kubectl describe pod hello-server | sed -n "/Containers:$/,/Conditions:/p"
```

Buscando el campo `Requests`, deber칤amos ver ahora un valor inferior en 
cuanto a CPU se refiere, lo que significar칤a que el VPA ha entrado
en acci칩n y ha hecho lo que deb칤a (dada la falta de actividad).


### 5. Autoescalado del cluster

El auto-escalador de cluster (o Cluster Autoscaler) est치 dise침ado
para a침adir o eliminar nodos en funci칩n de la demanda del servicio.
Esto nos permitir치 mantener una alta disponibilidad de nuestro
cluster haciendo posible evitar costes desorbitados asociados
con el mantenimiento de muchas instancias innecesarias.
Para activar el autoescalado (horizontal) de cluster lo 칰nico
que tenemos que hacer es:

```shell
$ gcloud beta container clusters update $cluster_name \
  --enable-autoscaling 
  --min-nodes 1 \
  --max-nodes 5
```

Esta tarea tardar치 unos minutos en completarse. Pero, esto
nos lleva a la siguiente pregunta: 
쮺칩mo se decidir치 cuando crear o destruir un nodo?
Para ello podemos seleccionar un perfil de autoescalado:

- *Balanced*: El seleccionado por defecto
- *Optimize-utilization*: Prioriza la optimizaci칩n de la utilizaci칩n
  sobre el mantenimiento de recursos disponibles. Es decir,
  el cluster autoescalar치 de manera mas agresiva, ya que no va 
  a priorizar tener alg칰n nodo por si acaso unos segundos m치s, 
  por lo que veremos una eliminaci칩n m치s r치pida de nodos.
  
Para cambiar a 칠ste 칰ltimo perfil, podemos usar el siguiente
comando:

```shell
$ gcloud beta container clusters update $cluster_name \
--autoscaling-profile optimize-utilization
```

Para comprobar los nodos disponibles podemos usar:

```shell
$ kubectl get nodes
```

Aunque tambi칠n podemos usar el portal web para verlo de una forma
m치s gr치fica.


### 6. Auto aprovisionamiento de nodos
El autoescalado NAP consiste en a침adir nuevos nodos al pool
de nodos asociado al cluster, pero con el tama침o adecuado para
adaptarse a la demanda. En ausencia de NAP, el autoecalador
de cluster crear칤a nodos con las mismas caracter칤sticas
de los ya existentes, no adapt치ndose as칤 verticalmente a la
demanda. Es por ello que el NAP es tan conveniente para un
uso adecuado de los recursos, m치s a칰n cuando tenemos cargas
de trabajo que son secuenciales (por *batches*), ya que 
con este modo de escalamiento el pool est치 optimizado para
nuestro caso de uso espec칤fico.

Para activar NAP en nuestro cluster:

```shell
gcloud container clusters update $cluster_name \
    --enable-autoprovisioning \
    --min-cpu 1 \
    --min-memory 2 \
    --max-cpu 45 \
    --max-memory 160
```

Donde estamos especificando el m칤nimo y m치ximo n칰mero de recursos
de CPU y memoria. Recordemos que esta estrategia es aplicable
al cluster completo. El NAP puede tardar unos minutos en activarse,
y a pesar de ello, puede ser que en nuestro ejemplo no entre en
juego dado el estado actual de nuestro cluster.

### Liberaci칩n de los recursos

Para borrar el cl칰ster, solo tenemos que ejecutar:

```shell
gcloud container clusters delete $cluster_name --quiet
```

El proceso de borrado del cl칰ster puede llevar unos minutos.
Este borrado tambi칠n se podr칤a haber hecho mediante [clean.sh](clean.sh):

```shell
chmod a+x clean.sh && ./clean.sh
```


